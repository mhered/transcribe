1
00:00:00,000 --> 00:00:12,620
Gracias por estar acá, mira, lo que nosotros vamos a hacer en la charla de hoy es intentar

2
00:00:12,620 --> 00:00:17,180
utilizar redes neuronales de Yplenium utilizando un tipo de redes muy especial que son un tipo

3
00:00:17,180 --> 00:00:23,020
de redes neuronales recurrentes, una red neuronal recurrente muy especial para análisis de

4
00:00:23,020 --> 00:00:27,460
series temporales y voy a intentar explicar un poco el mecanismo que tienen estas redes,

5
00:00:27,460 --> 00:00:31,160
como es, utilizar estas redes y los resultados que conseguimos con ellas en unos casos de

6
00:00:31,160 --> 00:00:36,920
estudio que es analizar el consumo eléctrico de la ciudad de Soyer y de la isla de Tenerife,

7
00:00:36,920 --> 00:00:39,080
la ciudad de Soyer en Palma y Mallorca.

8
00:00:39,080 --> 00:00:44,040
Bueno quiero agradecer al Grupo El Gas que nos facilita los datos para hacer el estudio

9
00:00:44,040 --> 00:00:49,120
y estas son el grupo de personas que trabajamos en el departamento de ciencia de datos de

10
00:00:49,120 --> 00:00:55,040
APCL en Mallorca, al final vamos a poner los contactos para que alguna duda o algo que

11
00:00:55,040 --> 00:00:57,040
quieran saber nos contacten a nosotros.

12
00:00:57,040 --> 00:01:01,840
Entonces la idea es esta, nosotros vamos a ver análisis de series temporales con redes

13
00:01:01,840 --> 00:01:07,840
neuronales, en particular vamos a usar unas redes que se llaman LSTM, las voy a explicar

14
00:01:07,840 --> 00:01:12,960
un poco de detalle más adelante y entonces la idea de esto es que son ese tipo de redes

15
00:01:12,960 --> 00:01:17,680
que se hace con esto y cómo funcionan, esto nos va a ayudar a nosotros a ver qué tipo

16
00:01:17,680 --> 00:01:22,680
de problemas podemos utilizar y cuáles no podemos aplicar este tipo de redes, aquí

17
00:01:22,680 --> 00:01:28,640
está un poco el overview, vamos a definir que es una serie temporal formalmente, vamos

18
00:01:28,640 --> 00:01:34,640
a ver algunos modelos previos que se utilizan para compararlo, por qué utilizar redes neuronales,

19
00:01:34,640 --> 00:01:38,000
analizar los casos de estudio y hacer un pequeño sumario de lo que tenemos.

20
00:01:38,000 --> 00:01:43,480
Entonces rápidamente que es una serie temporal, pero primero es una serie de secuencias,

21
00:01:43,480 --> 00:01:47,360
secuencia de datos y por qué es una serie temporal, porque esa secuencia de datos está

22
00:01:47,360 --> 00:01:53,760
tomada de manera temporales, ok, la mayoría de las veces esas tienen que estar espaciadas

23
00:01:53,760 --> 00:01:57,880
igualmente, entonces tengo una serie de datos, el cual están espaciados temporalmente, ya

24
00:01:57,880 --> 00:02:02,760
sea años, meses, no es obligatorio, pero lo mejor que se podría hacer es que tenga

25
00:02:02,760 --> 00:02:11,280
una misma espaciado, dado que cuando queremos ver comportamientos estacionales lo podemos

26
00:02:11,280 --> 00:02:16,880
recuperar fácilmente, cuando no tenemos esos datos habría que buscar la manera de hacer

27
00:02:16,880 --> 00:02:22,480
predicciones, rellenar esos datos, pero esas son los requisitos mínimos que tenemos,

28
00:02:22,480 --> 00:02:29,520
entonces recapitulando una serie temporal, es una serie secuencial tomado cronológicamente

29
00:02:29,520 --> 00:02:36,400
y entre lo que uno quiere llamar secuencias se encuentra, bueno, la secuencia del DNA,

30
00:02:36,400 --> 00:02:45,760
precios de la bolsa o cualquier otro tipo, por ejemplo, frases en una oración o algo

31
00:02:45,760 --> 00:02:51,200
similar, entonces previamente hay algunos otros modelos, yo le puse acá exagerando

32
00:02:51,200 --> 00:02:55,400
el lenguaje un enfoque tradicional, se sigue utilizando porque va a depender del tipo de

33
00:02:55,400 --> 00:03:00,600
señales, entonces los modelos tradicionales con que la mayoría de la gente intenta analizar

34
00:03:00,600 --> 00:03:05,120
series temporales son los que se conocen como modelos autoregresivos, de estos modelos

35
00:03:05,120 --> 00:03:10,120
autoregresivos hay un montón de ellos y cada uno es porque analiza diferentes partes de

36
00:03:10,120 --> 00:03:14,440
la señal con que yo voy a estudiar, tengo una señal temporal, se llama el autoregresivo

37
00:03:14,440 --> 00:03:19,280
porque voy a ver su propia historia y para mirar su propia historia tengo que ver diferentes

38
00:03:19,280 --> 00:03:25,000
partes de esa señal, cada uno de estas siglas va a representar qué parte de la señal

39
00:03:25,000 --> 00:03:29,160
estoy analizando, si yo quiero por ejemplo cojo este modelo que es el que más se utiliza,

40
00:03:29,160 --> 00:03:33,960
se llama modelo Arima, son modelos autoregresivos, autoregresivos porque están mirando su propia

41
00:03:33,960 --> 00:03:40,440
historia de un punto que yo parto hacia atrás, integrado porque yo voy a integrar en esa

42
00:03:40,440 --> 00:03:51,720
señal todas las partes estacionales, sea a corto plazo y largo plazo, y ese se llama

43
00:03:51,720 --> 00:03:56,080
estacional porque yo quiero ver por ejemplo si es anual, si se repite esa estacionalidad

44
00:03:56,080 --> 00:04:01,640
a un año, a dos años, a tres años depende de la longitud de los datos, todo lo que

45
00:04:01,640 --> 00:04:05,480
quieran saber es hacer series temporales están en este texto, por eso que no me voy a extender,

46
00:04:05,480 --> 00:04:11,140
aquí están todos, están en castellano y en inglés, entonces aquí tenemos algunos

47
00:04:11,140 --> 00:04:18,680
modelos, funciona parece que va bien pero muchas veces no, el 70% de las señales la

48
00:04:18,680 --> 00:04:23,840
gente quiere aplicar análisis para la bolsa por ejemplo y tiene este problema que no podemos

49
00:04:23,840 --> 00:04:30,320
predecir, entonces la idea es por qué yo voy a cambiar el enfoque, bueno por qué voy

50
00:04:30,320 --> 00:04:37,160
a cambiar el enfoque porque al principio cuando usamos redes, perdón, modelos autoregresivos

51
00:04:37,160 --> 00:04:42,120
tenemos que aplicar este flujo en el algoritmo que está acá que parece bastante complicado

52
00:04:42,120 --> 00:04:46,480
por qué, porque tenemos que analizar todos los que se llaman los correlogramas que me

53
00:04:46,480 --> 00:04:52,320
van a permitir saber todos los comportamientos de la función de autocorrelación parcial

54
00:04:52,320 --> 00:04:57,840
y global, qué quiere decir eso, que yo quiero ver qué parte de la señal está correlacionada,

55
00:04:57,840 --> 00:05:02,200
por ejemplo si una parte de la señal sube, tengo que ver eso está correlacionado con

56
00:05:02,200 --> 00:05:09,240
tiempos anteriores y está subió bajo también y quiero ver, cuando digo global quiero ver

57
00:05:09,240 --> 00:05:15,040
qué pasa en muchas partes, en muchas lugares de la señal y cuando digo local quiero reducir

58
00:05:15,040 --> 00:05:20,760
los espacios más pequeños, entonces todo esto es analizar todos estos diagramas, todos

59
00:05:20,760 --> 00:05:25,120
estos correlogramas hay que construirlo, después hay que construirlo hay que analizarlo

60
00:05:25,120 --> 00:05:30,000
y una vez que sabemos cuáles son los correlogramas tenemos que decidir qué tipo de los modelos

61
00:05:30,000 --> 00:05:34,760
de la lista que estuve anterior utilizar y eso no es una carea fácil, porque ya nos

62
00:05:34,760 --> 00:05:39,360
cuesta nosotros como humanos decidir cuál es el modelo de utilizar viendo los correlogramas

63
00:05:39,360 --> 00:05:43,960
imagínate tener que entrenar o analizar eso, o eso es auto que una máquina lo haga automáticamente

64
00:05:43,960 --> 00:05:50,800
entonces, por eso utilizamos las redes neuronales porque podemos que la misma red intente analizar

65
00:05:50,800 --> 00:05:56,920
qué tipo de partes de las señales va a utilizar para poder reproducir esas correlaciones,

66
00:05:56,920 --> 00:06:01,800
por un lado y por otro lado que aquí lo puse en rojo que es más importante es reconocer

67
00:06:01,800 --> 00:06:06,880
que los modelos autoregresivos solo dependen de su propia señal, solo pueden mirar su

68
00:06:06,880 --> 00:06:12,000
propia historia, las redes neuronales como yo le voy a meter matrices que en realidad

69
00:06:12,000 --> 00:06:16,840
no solo leí los matemáticos, los físicos le llamamos matrices, le llamamos tensores

70
00:06:16,840 --> 00:06:21,280
es porque me va a permitir meter mucha información, vamos a meter una matrícula, la matrícula

71
00:06:21,280 --> 00:06:26,560
vamos a tener muchos datos, la serie temporal y otras variables externas que podrían estar

72
00:06:26,560 --> 00:06:30,600
correlacionados con el comportamiento de las señales, entonces eso es lo importante de

73
00:06:30,600 --> 00:06:34,200
poder hacer este nuevo enfoque que nosotros vamos a hacer acá.

74
00:06:34,200 --> 00:06:37,800
Ahora voy a pasar que yo voy a utilizar las redes neuronales, pero voy a hacer una red

75
00:06:37,800 --> 00:06:41,520
neuronal, un tipo muy especial que se llama redes neuronales recurrentes, para ello voy

76
00:06:41,520 --> 00:06:47,400
a hacer muy rápido ningún detalle que es una reneuronar, entonces básicamente aquí

77
00:06:47,400 --> 00:06:55,560
yo voy a hablar de un perceptron, que es, esto va a simular una neurona, una neurona lo

78
00:06:55,560 --> 00:07:00,320
que hace es que tiene un montón de entradas, hace una función esa neurona y me da una

79
00:07:00,320 --> 00:07:04,920
salida y esa salida quiere decir que si la neurona se dispara o no y me deja pasar información

80
00:07:04,920 --> 00:07:10,040
después que ella tenga un umbral de activación y esto solo simulamos en la siguiente manera,

81
00:07:10,040 --> 00:07:14,040
tenemos un integrador que quiere decir que yo tengo un montón de entradas, los datos

82
00:07:14,040 --> 00:07:19,080
de entrada, esos datos de entrada van a estar puesto por un peso que lo voy a llamar W1

83
00:07:19,080 --> 00:07:24,880
o W2, W3, voy a tener una función integradora que en este caso es la suma, el va a sumar

84
00:07:24,880 --> 00:07:33,040
y una función de activación que puede ser de diferente forma, puede ser una sigmoide

85
00:07:33,040 --> 00:07:41,960
o una tangente hiperbólica, una lineal, una reloj dependiendo de diferente forma, qué

86
00:07:41,960 --> 00:07:47,280
quiere decir eso, que él va a evaluar, toda la información que le llega a una neurona

87
00:07:47,280 --> 00:07:51,200
integra toda esa información, va a evaluar si esa está por debajo o por encima de un

88
00:07:51,200 --> 00:07:56,040
umbral y me va a dejar pasar información para la siguiente neurona. Ahora yo no tengo

89
00:07:56,040 --> 00:08:01,800
una sola de esas, si no construyo una capa, tengo la red de entrada y yo voy a tener

90
00:08:01,800 --> 00:08:05,640
cada una de estas capas que están acá y entonces yo voy a tener aquí un conjunto

91
00:08:05,640 --> 00:08:10,520
de pesos que van de esta capa hacia esta capa, de esta capa hasta esta capa y de esta

92
00:08:10,520 --> 00:08:15,440
capa hasta esta capa, entonces lo que yo voy a tener es este mismo comportamiento por

93
00:08:15,440 --> 00:08:22,320
multiplicado por todas las n nodos en las n capas que yo puedo tener. Decimos que tenemos

94
00:08:22,320 --> 00:08:27,200
que entrenar la red, ¿qué significa entrenar la red? Para yo saber, para entrenar la red

95
00:08:27,200 --> 00:08:32,720
yo quiero es, yo le meto una entrada, espero una salida y compado, porque esto es un aprendizaje

96
00:08:32,720 --> 00:08:36,960
supervisado para el caso de reconocimiento, por ejemplo de patrones. Yo le poso una imagen

97
00:08:36,960 --> 00:08:41,280
como en la charla anterior, yo le pasaba una de imágenes, que él tenía que evaluar si

98
00:08:41,280 --> 00:08:45,560
se lo estaba haciendo o lo estaba haciendo mal, si la imagen era correcta o no, a partir

99
00:08:45,560 --> 00:08:49,800
de ahí me dan los resultados. Yo calculo ese error que aplico entre muchos algoritmos

100
00:08:49,800 --> 00:08:53,640
uno que se llama el back propagation, ¿qué quiere decir? Que yo compado el error en la

101
00:08:53,640 --> 00:09:01,400
salida de la red con el target y miro el error que está aquí, bueno que se llama el descendiente

102
00:09:01,400 --> 00:09:06,680
de gradientes y yo voy a calcular la derivada de cómo cae el error y voy a minimizar ese

103
00:09:06,680 --> 00:09:13,280
error entre la entrada y la salida, no es difícil pero hay muchas derivadas que hacer,

104
00:09:13,280 --> 00:09:18,040
porque lo tengo que hacer para cada uno de los pesos, yo voy a ver cómo voy a modificar

105
00:09:18,040 --> 00:09:25,360
esos pesos en cada una de los links que tiene cada una de las redes, entonces imagínate,

106
00:09:25,360 --> 00:09:29,520
para cada uno de ellos tengo que hacer todo este cálculo pero no solo para la primera

107
00:09:29,520 --> 00:09:32,720
capa sino para la capa siguiente, la capa siguiente, la capa siguiente, entonces ahora

108
00:09:32,720 --> 00:09:38,400
vamos a tener unas ecuaciones muy grandes que tenemos que ir minimizando con todo esto,

109
00:09:38,400 --> 00:09:43,400
pues esto es básicamente cómo funciona una red, lo que pasa es que para nosotros analizar

110
00:09:43,400 --> 00:09:48,760
series de secuencias tenemos que cambiar la red para otro tipo de red que la vamos a

111
00:09:48,760 --> 00:09:53,400
llamar series redes neuronales recurrentes, ¿qué son estas redes neuronales recurrentes?

112
00:09:53,400 --> 00:09:59,520
Es una red neuronal el cual yo le voy a meter un dato, ella tiene que dar una salida pero

113
00:09:59,520 --> 00:10:03,720
la salida tiene que volver a entrar en la red y tiene que volver a evaluarla, entonces

114
00:10:03,720 --> 00:10:07,880
lo que yo voy a poner es una recursividad que está aquí adentro, esa misma red se

115
00:10:07,880 --> 00:10:12,520
va a llevar a sí misma, son un modelo iterativo desde el punto de vista matemático que tenemos

116
00:10:12,520 --> 00:10:18,360
aquí, estamos deshaciendo este loop y cuando vemos este loop lo que tenemos es la red y

117
00:10:18,360 --> 00:10:25,160
va a ser tantas veces yo introduzca la serie temporal, él va a crear diferentes capas,

118
00:10:25,160 --> 00:10:29,040
obviamente que no es que estoy yo construyendo diferentes capas sino la misma red se va a

119
00:10:29,040 --> 00:10:35,640
llamar a sí misma recursivamente, por tanto yo voy a tener tantas capas como serie temporal

120
00:10:35,640 --> 00:10:41,480
larga yo introduzco para analizar, entonces se nos complica aquí bastante, luego tenemos

121
00:10:41,480 --> 00:10:48,760
un problema cuando queremos analizar series temporales muy largas, que es el problema del

122
00:10:48,760 --> 00:10:53,280
gradiente, del desaparecimiento del gradiente o la explosión del gradiente, ¿qué quiere

123
00:10:53,280 --> 00:10:54,280
decir?

124
00:10:54,280 --> 00:10:58,240
Les había dicho que para entrenar la red yo tengo que calcular como minimizar un error

125
00:10:58,240 --> 00:11:04,160
entre la entrada y la salida y ojo que aquí ya estoy calculando, yo miro la salida de

126
00:11:04,160 --> 00:11:09,160
esta y veo el error que ha cometido aquí, tengo que calcularlo luego, entro a este dato

127
00:11:09,160 --> 00:11:12,560
aquí tengo que ver también su error y así sucesivamente, por tanto yo tengo, voy a

128
00:11:12,560 --> 00:11:17,440
tener un error global de todo esto que es muy grande, pero como esta matriz se está

129
00:11:17,440 --> 00:11:22,520
llamando así misma los autobalores de esa matriz, el término matemático va a ser que

130
00:11:22,520 --> 00:11:25,400
aumente mucho, ¿qué quiere decir en un lenguaje más terrenal?

131
00:11:25,400 --> 00:11:31,640
Que el error de la matrifa va a caer muy rápido a cero o va a ir muy rápido a infinito,

132
00:11:31,640 --> 00:11:35,640
por tanto yo no voy a poder modificar los pesos porque no sé cómo moverlos, por tanto

133
00:11:35,640 --> 00:11:41,120
la red no va a prender, entonces la red recurrente cuando yo voy a analizar series temporales

134
00:11:41,120 --> 00:11:48,760
muy largas y que no mantienen un patrón cítlico muy establecido, tienen el problema de que

135
00:11:48,760 --> 00:11:54,960
puede ocurrir que el error se vaya muy rápido a cero o vaya muy rápido a infinito, por

136
00:11:54,960 --> 00:12:00,520
tanto no voy a poder modificar los pesos, entonces para ello se crea otro tipo de red

137
00:12:00,520 --> 00:12:07,880
que se llama la Long Shunt and Memory Network, por eso las LSTM y es una red que es un tipo

138
00:12:07,880 --> 00:12:13,920
de red muy especial que nos va a permitir intentar resolver este problema, ¿qué quiere

139
00:12:13,920 --> 00:12:15,880
decir que va a intentar resolver este problema?

140
00:12:15,880 --> 00:12:21,040
Vamos a intentar no tener multiplicación de las matrices de errores de cada una de ellas

141
00:12:21,040 --> 00:12:26,360
sino buscar una forma que transforme esas multiplicaciones de matrices en suma, ok, la

142
00:12:26,360 --> 00:12:30,680
parte matemática me la salto un poco, pero lo que yo voy a hacer es que cada una de

143
00:12:30,680 --> 00:12:35,080
las capas de esa red neuronal, cada una de estas son las capas de la red neuronal, la

144
00:12:35,080 --> 00:12:40,360
voy a sustituir por lo que llamamos una celda de memoria, ¿y qué es una celda de memoria?

145
00:12:40,360 --> 00:12:45,720
Una celda de memoria, voy a saltar esta lámina, disculpen, una celda de memoria es este tipo

146
00:12:45,720 --> 00:12:51,440
de cosas, es cada capa de esas yo la voy a sustituir por cuatro capas de red neuronal,

147
00:12:51,440 --> 00:12:56,400
si ustedes ven aquí, esta es la estructura de una red neuronal, tengo las entradas, la

148
00:12:56,400 --> 00:13:01,280
función integradora, la función de activación y una salida, ok, pero para esa red yo le

149
00:13:01,280 --> 00:13:06,800
voy a meter tres tipos de entradas, una cosa que yo voy a llamar una información que es

150
00:13:06,800 --> 00:13:12,520
la memoria previa que tiene la red de lo que ha ocurrido anteriormente, voy a poner la

151
00:13:12,520 --> 00:13:18,760
salida que yo quiero, si, perdón la salida que ella me predijo en el tiempo anterior

152
00:13:18,760 --> 00:13:22,360
y el dato que estoy metiendo ahora mismo, recuerden que esto puede ser vectores de

153
00:13:22,360 --> 00:13:26,960
datos, entonces esto ya empieza a escalar, empieza a ser bastante grande, aquí tenemos

154
00:13:26,960 --> 00:13:31,880
las entradas o los input, luego que tengo de salida, tengo dos salidas, el nuevo bloque

155
00:13:31,880 --> 00:13:36,600
de memoria que va a ser modificada o no, que voy a explicar en detalle eso y la salida

156
00:13:36,600 --> 00:13:41,960
que va a ser la salida que toque para esa celda y la salida que va a entrar a la otra

157
00:13:41,960 --> 00:13:46,480
celda siguiente, no sé si queda claro más o menos el esquema, ya lo voy a explicar un

158
00:13:46,480 --> 00:13:53,480
poco en detalle cada uno que hace, lo primero es que lo más importante que tiene esta celda

159
00:13:53,480 --> 00:14:07,520
es lo que nosotros llamamos la celda de memoria, eso es donde me va a guardar un vectorcito

160
00:14:07,520 --> 00:14:12,360
que me va a guardar información de lo que está ocurriendo en lo que la red de alguna

161
00:14:12,360 --> 00:14:19,240
manera va a aprender que es importante en tiempos locales o tiempos muy a muy larga

162
00:14:19,240 --> 00:14:24,720
distancia, por ejemplo el simil podría ser un historiador, cuando un historiador va a

163
00:14:24,720 --> 00:14:30,040
intentar predecir qué va a ocurrir en la historia, él no analiza todos los hechos históricos,

164
00:14:30,040 --> 00:14:35,200
paso a paso lo que pasó, sino él va a intentar en una línea temporal poner las cosas más

165
00:14:35,200 --> 00:14:39,400
importantes de manera cronológica, de tal manera que le permiten hacer una predicción, pues

166
00:14:39,400 --> 00:14:44,360
más o menos esa es la idea que queremos hacer aquí, entonces esto es lo más importante,

167
00:14:44,360 --> 00:14:49,720
la celda de memoria, la parte de memoria, ¿qué tenemos? tenemos estas dos productos

168
00:14:49,720 --> 00:14:56,400
van a funcionar como un grifo que abre y cierra la información de lo anterior que yo tenía

169
00:14:56,400 --> 00:15:00,920
y lo voy a mezclar por otra información, entonces yo te imagino que esta memoria es

170
00:15:00,920 --> 00:15:07,280
un flujo que yo voy a modificar en el tiempo, ¿cómo lo modifico? tengo una celda que se

171
00:15:07,280 --> 00:15:13,400
llama el olvido que es, ve la información que estoy mintiendo ahora, la información

172
00:15:13,400 --> 00:15:17,360
que tenía antes iba a tener una función de activación para decir qué parte de esa

173
00:15:17,360 --> 00:15:22,720
información apago o no, esto se llama la válvula de olvido, luego tenemos otra válvula

174
00:15:22,720 --> 00:15:27,800
que es la válvula de información, que es lo que yo voy a decir, que nueva información

175
00:15:27,800 --> 00:15:36,000
necesito yo actualizar en el vector de memoria para hacer la siguiente predicción, y luego

176
00:15:36,000 --> 00:15:41,240
las dos funciones se mezclan aquí con la misma llavecita que yo tenía anteriormente,

177
00:15:41,240 --> 00:15:47,800
esta válvula y aquí me va a permitir que, perdón, me va a permitir que parte de esta

178
00:15:47,800 --> 00:15:50,880
información yo voy a mezclar y que parte de esta información que voy a mezclar, fin

179
00:15:50,880 --> 00:15:56,400
es que aquí cambié el color de la línea temporal de la memoria, porque va a ser modificada,

180
00:15:56,400 --> 00:16:01,280
pero va a depender de esta llave, de lo que ocurra aquí y de esta llave, puede ser que

181
00:16:01,280 --> 00:16:05,760
la información que yo tenía almacenada la necesito toda, entonces por tanto no la modifique,

182
00:16:05,760 --> 00:16:12,560
hoy voy a necesitar parte de la información que se borre o no, esto simplemente son convoluciones,

183
00:16:12,560 --> 00:16:17,600
son multiplicaciones de matrices y adiciones de matrices, va a depender de cómo es la información

184
00:16:17,600 --> 00:16:22,080
que yo ponga, ¿no? y luego tengo las válvulas de salida, la válvula de salida, ahora me

185
00:16:22,080 --> 00:16:28,480
va a decir, dada toda esta información, que parte de las neuronas creen que se active

186
00:16:28,480 --> 00:16:32,440
o no, ¿no? de dado, yo voy a tener ahora una función de activación que aquí se me

187
00:16:32,440 --> 00:16:39,040
salte algo por lo rápido que iba, pero tú tienes una información que es la simoide,

188
00:16:39,040 --> 00:16:44,280
va entre 0 y 1, entonces me voy a decir, si hay valores que están por debajo de 0, no

189
00:16:44,280 --> 00:16:49,080
me permite pasar informaciones, si no se activan las neuronas y están por encima de 0, me

190
00:16:49,080 --> 00:16:53,480
va a permitir pasar la información, pero como es una función derivable, él va a considerar

191
00:16:53,480 --> 00:16:58,880
cuánto de esa información quiere que pase o no, ¿ok? Entonces finalmente tenemos esto,

192
00:16:58,880 --> 00:17:02,760
imaginemos ahora el flujo de información con cada una de las llavecitas donde abro y

193
00:17:02,760 --> 00:17:07,760
cierro la llave, donde hago las mezclas de todo y la salida que tengo, entonces realmente

194
00:17:07,760 --> 00:17:14,720
aquí es cómo funciona y yo lo que voy a intentar ahora es calcular el error de todos

195
00:17:14,720 --> 00:17:20,200
estos pesos, fíjense que ahora tenemos muchas capas, tenemos para la celda, lo vemos este

196
00:17:20,200 --> 00:17:27,440
en mi mejor dibujo, para la celda de entrada de información, la celda de olvido y la celda

197
00:17:27,440 --> 00:17:34,400
o la puerta de olvido, de entrada de información y de salida, son ahora cuatro redes neuronales

198
00:17:34,400 --> 00:17:38,720
que están acopladas entre ellas, ya no es una sola, son cuatro redes neuronales que

199
00:17:38,720 --> 00:17:43,560
han a funcionar de esta manera y que están cada una con sus pesos en las capas correspondientes.

200
00:17:43,560 --> 00:17:49,560
Luego como yo voy a tener esta que es la más importante, yo en vez de convertir la multiplicación

201
00:17:49,560 --> 00:17:54,400
de todo esto, pase a tener sumas, tengo la suma de esta capa que va a ser, ¿qué parte?

202
00:17:54,400 --> 00:17:58,000
Acuérdente que f es la parte de olvido, ¿qué parte de la información cree que es

203
00:17:58,000 --> 00:18:02,040
el olvido? No va a ser multiplicado por la memoria que yo tenía anteriormente y luego

204
00:18:02,040 --> 00:18:06,720
aquí ¿cuánto es lo que yo voy a mezclar? Ahora yo tengo una suma y como tengo una suma

205
00:18:06,720 --> 00:18:10,720
cuando calculo la derivada de los errores no me va a explotar porque la derivada de

206
00:18:10,720 --> 00:18:14,800
la suma es la suma de las derivadas, no tengo que ir a la potencia de nada y entonces eso

207
00:18:14,800 --> 00:18:20,080
me va a permitir a que el error no explote, ahora eso en la teoría suena muy bien, pero

208
00:18:20,080 --> 00:18:27,200
tenemos un problema que a veces la válvula del olvido dependiendo del tipo de la serie

209
00:18:27,200 --> 00:18:33,080
puede ser cero y cuando es cero tenemos el problema de que puede explotar el error porque

210
00:18:33,080 --> 00:18:36,400
el error cae muy rápido, ¿no? Entonces se va a depender también del tipo de serie

211
00:18:36,400 --> 00:18:40,040
de la final que tenemos. Entonces finalmente cuando hablamos de una

212
00:18:40,040 --> 00:18:46,080
D-Line tipo el STM estamos haciendo una cosa de esta, por ejemplo una red de tres por tres

213
00:18:46,080 --> 00:18:53,200
en donde cada una de ellas son cuatro redes neuronales acopladas en cada una de las cenas,

214
00:18:53,200 --> 00:18:58,960
es decir hemos sustituido cada una de las capas de una red neuronal normal por todas

215
00:18:58,960 --> 00:19:03,680
estas capas, por todas estas redes neuronales, entonces tenemos algo heavy, bastante pesado

216
00:19:03,680 --> 00:19:11,680
para la parte del cálculo, ¿ok? Y creo que esto es la parte técnica ya la...

217
00:19:11,680 --> 00:19:18,200
Bueno, para el caso de estudio de la población de Söyer vemos aquí el dataset que vendría

218
00:19:18,200 --> 00:19:25,480
a ser fecha de consumo, el consumo eléctrico y la temperatura por horas, esos son los

219
00:19:25,480 --> 00:19:35,480
datos, el consumo, la suma de todos los clientes de la población en esa hora. Entonces aquí

220
00:19:35,480 --> 00:19:43,800
podemos ver representado gráficamente durante varios meses y vemos como obviamente la temperatura

221
00:19:43,800 --> 00:19:51,520
tiene una correlación con el consumo eléctrico por motivos, bueno, sobre todo para aparatos

222
00:19:51,520 --> 00:19:58,960
de climatización, ¿vale? Entonces qué maneras tenemos nosotros de la arquitectura del STM

223
00:19:58,960 --> 00:20:05,800
porque ha comentado Juan Carlos las diferentes entradas que le puedes poner, pero dependiendo

224
00:20:05,800 --> 00:20:14,480
de tu caso de uso, pues vas a usar un tipo de arquitectura otra. Aquí para no extenderme

225
00:20:14,480 --> 00:20:21,000
mucho las más comunes son la de MENI2-1 y la de MENI2-MENI, por ejemplo, la más famosa

226
00:20:21,000 --> 00:20:27,440
MENI2-MENI porque mucha gente que utiliza este tipo de red para generar textos, por ejemplo

227
00:20:27,440 --> 00:20:32,920
ayer estuve viendo uno que generaban capítulos de juego de tronos a partir de todos los libros

228
00:20:32,920 --> 00:20:40,480
antiguos y otra gente que por ejemplo cogía canciones de metálica y con los patrones

229
00:20:40,480 --> 00:20:46,480
de batería genera otros nuevos patrones de batería, pues eso utilizan en la MENI2-MENI.

230
00:20:46,480 --> 00:20:53,840
En nuestro caso lo que usamos es MENI2-1 porque cogemos un histórico de consumo y de temperatura

231
00:20:53,840 --> 00:20:59,560
y predecimos el consumo eléctrico de la siguiente hora. ¿Cómo funciona esto? Entonces nosotros

232
00:20:59,560 --> 00:21:05,000
lo que tenemos es lo que se llama el look back, entonces el look back viene a ser cuánto

233
00:21:05,000 --> 00:21:11,360
voy a consultar yo del histórico de consumo y de temperatura para usar esos datos para

234
00:21:11,360 --> 00:21:18,760
mi predicción. Entonces lo que tenemos hecho es que vamos cogiendo los datos y vamos desplazando

235
00:21:18,760 --> 00:21:24,520
de cara a que nosotros cogemos los datos, hacemos la predicción pero si queremos saber

236
00:21:24,520 --> 00:21:32,240
cuál es la predicción de la siguiente hora concatenamos todo lo que teníamos con el

237
00:21:32,240 --> 00:21:40,480
consumo predicho en una hora y podemos predecir la siguiente hora. Entonces sería este esquema,

238
00:21:40,480 --> 00:21:47,640
vamos desplazando los datos para ir predeciendo datos. Para hacer todo esto obviamente no

239
00:21:47,640 --> 00:21:54,080
nos hemos puesto a hacerlo a mano sino que hay gente que ya se ha pegado el curro y ha

240
00:21:54,080 --> 00:21:59,680
implementado librellas para poder usar todo este tipo de cosas. Una de ellas es el Keras

241
00:21:59,680 --> 00:22:06,320
que inicialmente solo soportaba Ateano pero ahora soporta TensorFlow y incluso el nuevo

242
00:22:06,320 --> 00:22:12,040
framework de Microsoft, vamos, que es una pasada porque es una manera de hacer todo

243
00:22:12,040 --> 00:22:17,760
el tema de redes no solo recurrentes sino de redes neuronales y de convulucionales y

244
00:22:17,760 --> 00:22:25,720
de todo tipo con muy pocas líneas de código. De hecho es tan popular que incluso Google

245
00:22:25,720 --> 00:22:31,080
ha fichado al tío y ya se han metido ahí. Como nosotros somos bastante vaguetes hay

246
00:22:31,080 --> 00:22:37,640
que hacerlo en código así rápido. Entonces vemos aquí que vamos configurando nuestra

247
00:22:37,640 --> 00:22:44,640
red con el loopback, lo que he explicado antes y otras parámetros de la red como el batch

248
00:22:44,640 --> 00:22:51,440
size, el número de celas, etcétera. Entonces es muy simple porque simplemente declaramos

249
00:22:51,440 --> 00:22:57,840
un modelo secuencial y vamos añadiendo capas el STM. Importante que luego tiene la última

250
00:22:57,840 --> 00:23:04,200
capa el dense one que lo que hace es que eso dice que la última salida o sea es de un

251
00:23:04,200 --> 00:23:11,200
valor. Y luego se configura nuestros parámetros como el loss que viene a ser la función de

252
00:23:11,200 --> 00:23:16,720
error y el optimizador que en este caso es adam pero se puede utilizar esto castigradient

253
00:23:16,720 --> 00:23:24,160
descent y tal. Entonces hacemos el fit que eso tarda bastante porque las lstm tardan

254
00:23:24,160 --> 00:23:29,120
bastante y luego hacemos predic y podemos conseguir cosas como esta. Esto vendría a

255
00:23:29,120 --> 00:23:39,480
ser de una semana con un loopback de 60 y vemos que se ajusta bastante bien. Y luego

256
00:23:39,480 --> 00:23:46,440
si aumentamos el loopback o sea miramos 560 horas atrás pues evidentemente nuestra red

257
00:23:46,440 --> 00:23:51,240
tiene como más memoria para así decirlo. Entonces la predicción es más fina. Aquí

258
00:23:51,240 --> 00:23:57,920
podemos ver ya a nivel más preciso, a nivel de horas con el intervalo de confianza y vemos

259
00:23:57,920 --> 00:24:06,240
como se ajusta bastante bien y también le hicimos el mismo experimento para tener ife

260
00:24:06,240 --> 00:24:12,400
con datos meteorológicos aparte como la temperatura, humedad, el viento y vemos también como

261
00:24:12,400 --> 00:24:18,280
se ajusta muy bien. No solo era para bueno ya funciona en el sol y ya está no pues hicimos

262
00:24:18,280 --> 00:24:25,080
un ejemplo sacado de la red eléctrica española y podemos ver que se ajusta muy bien. Entonces

263
00:24:25,080 --> 00:24:31,480
esto es el caso de estudio para concluir. Para hacer un sumario, un detallito acá lo

264
00:24:31,480 --> 00:24:36,000
que usamos aparte de la serie temporal de Soyer solo teníamos un año, aquí podemos

265
00:24:36,000 --> 00:24:40,160
utilizar cuatro años de serie temporal, eso nos ayuda también porque vamos a tener más

266
00:24:40,160 --> 00:24:44,920
información histórica. Entonces el sumario que lo que hicimos nosotros estamos introduciendo

267
00:24:44,920 --> 00:24:51,160
aquí un enfoque alternativo al uso de los modelos comúnmente utilizados que son los

268
00:24:51,160 --> 00:24:58,080
autoregresivos que utilizando redes negronales recurrente, las LCTM, como una herramienta

269
00:24:58,080 --> 00:25:05,200
adicional, ojo como toda red neuronal para que la red neuronal pueda decir cosas interesantes

270
00:25:05,200 --> 00:25:12,760
tiene que tener mucho datos de entrenamiento, a veces no podemos utilizar esta aproximación

271
00:25:12,760 --> 00:25:18,520
si no tenemos suficiente datos para poder entrenar la red, eso es algo obvio pero lo

272
00:25:18,520 --> 00:25:24,720
quiero decir acá porque si no tenemos que seguir utilizando las herramientas de autoregresión.

273
00:25:24,720 --> 00:25:28,280
Lo que hemos hecho es sustituir las celdas normales por celdas de memoria que ya las

274
00:25:28,280 --> 00:25:33,120
expliqué que eran, esas celdas de memoria facilitan tener información a corto y largo

275
00:25:33,120 --> 00:25:38,560
plazo de la serie, resuelve el problema en parte, no totalmente en la práctica, en

276
00:25:38,560 --> 00:25:48,040
la teoría si lo resuelves pero en la práctica no, ok, depende del tipo de señal y que mejora

277
00:25:48,040 --> 00:25:54,120
la predicción porque podemos utilizar múltiples capas de entrada, es decir que podemos utilizar

278
00:25:54,120 --> 00:26:01,200
factores externos que tienen que ver con el comportamiento de la señal, cosas que no

279
00:26:01,200 --> 00:26:06,400
lo podemos hacer con la bolsa e impredecir la bolsa porque nosotros no podemos manejar

280
00:26:06,400 --> 00:26:11,560
todas las variables externas que modifican, entonces no es porque cuando hicimos esto

281
00:26:11,560 --> 00:26:15,480
mucha gente nos dijo en la empresa ya está, nos metemos como grokel y nos vamos a hacer

282
00:26:15,480 --> 00:26:19,000
ricos, no, tendríamos que ver que está pasando en el mundo con todas las variables

283
00:26:19,000 --> 00:26:26,080
en insistente y entrenarla, y sobre todo agradecer a la gente del gas que no ha permitido utilizar

284
00:26:26,080 --> 00:26:46,280
sus datos para este trabajo, no sé si queda tiempo para alguna pregunta, no, entonces ya no está bien.

285
00:26:46,280 --> 00:26:57,280
Ahora no voy a decir que la jala pero luego si nos importa echarnos un par de metidos o una pregunta.

