1
00:00:00,000 --> 00:00:23,080
Vamos a comenzar con la siguiente charla por Ramón, que es doctor ininformática y

2
00:00:23,080 --> 00:00:29,880
serios está ingeniar en Google. Viene desde Zurich, así que un fuerte aplauso para él para

3
00:00:29,880 --> 00:00:32,080
hacer la transición.

4
00:00:39,080 --> 00:00:47,080
Bueno, gracias, se oye bien. Yo como me han presentado soy Ramón, alguno de vosotros conocéis esta página.

5
00:00:47,080 --> 00:00:56,080
Yo soy el tiel, el technical leader del equipo de SRIN que soporta este servicio. Este servicio

6
00:00:56,080 --> 00:01:03,080
solo tiene este frontend, nada más que puedes meter tu usuario y tu contraseña. Detrás tenemos...

7
00:01:03,080 --> 00:01:13,080
¿Qué? Vale, pensé que me decía algo de que no se oía. Detrás tenemos como... hay 160 micro-servicios.

8
00:01:13,080 --> 00:01:21,080
El storage principal, hay varios, hace 250 millones de consultas por segundo y tenemos algunos modelos

9
00:01:21,080 --> 00:01:26,080
de Machine Learning, ya que está de moda, por ejemplo, para la prevención de hijacking, para que no os roben las cuentas,

10
00:01:26,080 --> 00:01:34,080
ni os impersonalicen, ni os roben las cookies y los credenciales. Y esto es algo que nos dedicamos.

11
00:01:34,080 --> 00:01:41,080
El desarrollo que hacemos, creo que es conocido que en Google tenemos un monorrepo que tiene más de 1000 millones

12
00:01:41,080 --> 00:01:47,080
de líneas de códigos, 30 millones de commits y desde ahí se despliega todo, millones de máquinas

13
00:01:47,080 --> 00:01:52,080
que están distribuidas en decenas de centros de datos por el mundo. Python es una herramienta

14
00:01:52,080 --> 00:02:00,080
que es clave para la gestión de todo el DevOps que hacemos en estos servicios. Pero no solo para eso.

15
00:02:00,080 --> 00:02:06,080
Por ejemplo, el frontend de YouTube originalmente estaba escrito en Python. Entonces, os voy a contar

16
00:02:06,080 --> 00:02:12,080
un poco mi vida de que es EsaRi y luego hablamos de Python. ¿Quién tiene familiaridad con el término EsaRi?

17
00:02:12,080 --> 00:02:18,080
Bueno, bien, bien, fantástico. EsaRi, al final, es una implementación de DevOps, como veréis aquí.

18
00:02:18,080 --> 00:02:24,080
Pero básicamente, en esta charla anterior, tenemos como dos mundos. Tenemos los desarrolladores,

19
00:02:24,080 --> 00:02:30,080
que quiere un desarrollador, cuantas más features, más rápido, mejor. Si queréis escribir un feature

20
00:02:30,080 --> 00:02:35,080
y lo queréis poner en producción, si podéis hacer 10 releases cada día, mucho mejor que si podéis hacer uno cada semana.

21
00:02:35,080 --> 00:02:41,080
¿Qué queremos los operadores o qué queremos la gente de sistemas? Que el sistema sea lo más estable posible.

22
00:02:41,080 --> 00:02:46,080
¿Cuál es el sistema más estable que existe? El que no se toca. Si quieres un sistema que no tenga autiches,

23
00:02:46,080 --> 00:02:53,080
que no tenga incidentes, simplemente no lo toques. Es maravilloso. Tu negocio posiblemente dure poco, pero...

24
00:02:53,080 --> 00:02:59,080
El ciclo de desarrollo de software, al final lo que tenemos es un concepto. Hay gente de business

25
00:02:59,080 --> 00:03:05,080
que habla de cosas de business. Lo encontramos ya los desarrolladores en operaciones y al final es cuando

26
00:03:05,080 --> 00:03:08,080
ya tienes el servicio en producción, es cuando puedes monetizarlo y demás.

27
00:03:08,080 --> 00:03:15,080
A Yael vino a resolver un poco el gap que había entre la gente de business y developers,

28
00:03:15,080 --> 00:03:18,080
porque al principio la gente de business decía que desarrollarnos de qué herramienta,

29
00:03:18,080 --> 00:03:22,080
que desarrollarnos de qué producto y la gente de desarrollo decía así, en dos años está.

30
00:03:22,080 --> 00:03:30,080
Entonces, a Yael permite romper un poco esa barrera. Y DevOps resuelve el otro, es decir, el overlap

31
00:03:30,080 --> 00:03:35,080
entre las operaciones y el desarrollo. Esto supongo que seáis todos familiares con esto.

32
00:03:35,080 --> 00:03:41,080
Al final, los equipos de sarri son equipos que hacemos de DevOps. Yo siempre digo que DevOps es como

33
00:03:41,080 --> 00:03:47,080
una interfaz que nosotros tenemos que establece una serie de principios de infrastructure as code,

34
00:03:47,080 --> 00:03:51,080
automatización, todas estas cosas. Y sarri es una implementación particular que nos ha funcionado

35
00:03:51,080 --> 00:03:55,080
en Google y que en otras empresas también les ha podido funcionar. Hacemos cosas desde

36
00:03:55,080 --> 00:04:00,080
automatización, observabilidad, monitorización, pruebas de carga y diseñamos los sistemas.

37
00:04:00,080 --> 00:04:05,080
Por ejemplo, yo esta semana estaba revisando un diseño de alguien que quería añadir a uno

38
00:04:05,080 --> 00:04:11,080
de nuestros autenticadores, una de las cookies o de los tokens, quería extenderlo en 512 bytes.

39
00:04:11,080 --> 00:04:16,080
Y eso es bueno, pues no es mucho. El problema es que cuando tienes más de 90 o 100 millones

40
00:04:16,080 --> 00:04:23,080
de transacciones por segundo con esos identificadores, eso supone que puedes estar hablando de que

41
00:04:23,080 --> 00:04:28,080
tienes un incremento de uso de tu YGREX, de tu entrada de ancho de banda a tus sistemas de como

42
00:04:28,080 --> 00:04:33,080
entre 10 y 18 gigabytes por segundo, solo con ese cambio tan sencillo. Esa son una de las labores

43
00:04:33,080 --> 00:04:42,080
que sarri realiza. Lo que os decía DevOps es una interfaz general y sarri es una implementación.

44
00:04:42,080 --> 00:04:47,080
La diferencia o las dos claves que utilizamos en esa RISC que primero, todos somos ingenieros

45
00:04:47,080 --> 00:04:51,080
de software, bueno yo soy ingeniero de sistemas pero todos escribimos software. Entonces la

46
00:04:51,080 --> 00:04:56,080
gracia es cuando tienes un problema de operaciones y pones gente que escribe software que va a

47
00:04:56,080 --> 00:05:00,080
ocurrir, pues que van a escribir software para automatizarlo. Por lo tanto ya no hay operaciones,

48
00:05:00,080 --> 00:05:05,080
es un poco el intent. Y utilizamos indicadores de nivel de servicio para todo. Todos los

49
00:05:05,080 --> 00:05:11,080
servicios tienen un indicador de nivel de servicio y un objetivo, por ejemplo, uno de los servicios

50
00:05:11,080 --> 00:05:16,080
que más objetivo de nivel de servicio tiene de disponibilidad dentro de la empresa es el sistema

51
00:05:16,080 --> 00:05:21,080
que valida las cookies. Cuando vosotros accedéis a un servicio de Google, sea cual sea, utilizáis

52
00:05:21,080 --> 00:05:26,080
un API o lo que sea, siempre vais a presentar un token, un Verertoken, bien sea una cookie,

53
00:05:26,080 --> 00:05:31,080
un token DevOps, etcétera. Todos los servicios, todos los APIs dependen de ese servicio. Por lo

54
00:05:31,080 --> 00:05:37,080
tanto nosotros tenemos un servicio que tiene 6, 9 y medio de disponibilidad. Eso significa que

55
00:05:37,080 --> 00:05:44,080
solo puede tener un incidente como mucho de 250 milisegundos cada año. Lo que indica que

56
00:05:44,080 --> 00:05:49,080
el servicio tiene que estar desarrollado y diseñado para soportar todas estas cosas.

57
00:05:52,080 --> 00:05:54,080
¿Cuáles son las prácticas que utilizamos?

58
00:05:55,080 --> 00:06:00,080
Monitorización y alerta. Esto lo estábamos hablando, esta pregunta que le hice en esa anteriormente.

59
00:06:00,080 --> 00:06:05,080
¿Tú tienes que conocer cómo es tu servicio? Y tienes que conocer tu servicio a priori y a posteriori.

60
00:06:05,080 --> 00:06:09,080
A priori hay una serie de métricas que tú vas a desplegar y que tú vas a recolectar antes de que

61
00:06:09,080 --> 00:06:14,080
ocurra, antes de que el servicio esté en producción, la latencia. Yo que sé si es un modelo de machine

62
00:06:14,080 --> 00:06:18,080
learning, pues quizás haber algunas métricas específicas de la precisión de tu modelo y demás.

63
00:06:18,080 --> 00:06:23,080
Pero también a posteriori. Cuando tienes un incidente y tienes que entrar y depurar un stack de 150

64
00:06:23,080 --> 00:06:27,080
microservicios, tienes que tener herramientas que te permitan navegar por todos esos servicios

65
00:06:27,080 --> 00:06:32,080
para ver dónde está el problema. Pero nunca se va a marter y a dejar un problema de este

66
00:06:32,080 --> 00:06:36,080
microservicio. ¿Está mal? No, lo que va a ocurrir es que los usuarios no pueden utilizar un API X.

67
00:06:36,080 --> 00:06:41,080
Y luego 25 capas después de microservicios es donde el problema se encontraba. Tienes que tener

68
00:06:41,080 --> 00:06:45,080
herramientas para navegar esas cosas. Muchas de las herramientas que utilizamos en Google están

69
00:06:45,080 --> 00:06:48,080
desarrolladas en Paez. Como veremos después, unos casos de uso.

70
00:06:51,080 --> 00:06:57,080
En el cloud nadie tiene que hacer un forecast en una predicción de la capacidad, salvo si tú eres el cloud.

71
00:06:57,080 --> 00:07:03,080
Entonces es un problema interesante y es un problema en el que se aplican cosas de análisis de datos

72
00:07:03,080 --> 00:07:09,080
y demás. Por ejemplo, cuando uno tiene que desplegar un centro de datos completo, y eso ocurre,

73
00:07:09,080 --> 00:07:17,080
tienes que hacer cosas tan interesantes como comprar un terreno, contratar a gente que te lo construya,

74
00:07:17,080 --> 00:07:22,080
tienes que contratar varias líneas de fibra, tienes que contratar con varias utilities de electricidad

75
00:07:22,080 --> 00:07:30,080
y demás, tienes que comprar entre 20 y 100 mil máquinas, desplegarlas, instalarlas, y una vez ya puedes ejecutar

76
00:07:30,080 --> 00:07:35,080
tu software. Todavía hay una pila de software compleja, o sea que hasta que nosotros entramos en un centro

77
00:07:35,080 --> 00:07:41,080
de datos pueden pasar entre dos y tres años. Por lo tanto, hacer una predicción de cuál va a ser la demanda

78
00:07:41,080 --> 00:07:46,080
en la que vamos a tener de máquinas y demás a futuro es muy importante. Otra vez Paez ha ido aquí,

79
00:07:46,080 --> 00:07:51,080
por ejemplo, para hacer técnicas que utilizamos de series temporales, de la demanda que tienes en cada región,

80
00:07:51,080 --> 00:07:59,080
cómo va creciendo, es muy interesante para poder prevenir y decir, dentro de tres años vamos a necesitar cinco o seis localizaciones más,

81
00:07:59,080 --> 00:08:06,080
por ejemplo. Esto es lo que comentaba antes también, es diseñar los servicios para que sean eficientes.

82
00:08:06,080 --> 00:08:12,080
Y va desde el punto de vista de si tienes un binario en C++, por ejemplo, una cosa que hicimos hace un tiempo,

83
00:08:12,080 --> 00:08:18,080
teníamos un binario en C++ que era un monolito como así de grande y feo, y el binario solo era un fichero Elf,

84
00:08:18,080 --> 00:08:28,080
un ejecutable de Linux que eran 875 megas de código. Cargar eso en memoria y tal era un dolor cada vez que se tenía que reiniciar.

85
00:08:28,080 --> 00:08:37,080
Entonces, desde partirlo en binarios más pequeños, por ejemplo, o utilizar cosas como la huge page de Linux y demás,

86
00:08:37,080 --> 00:08:43,080
todas esas optimizaciones que buscan la eficiencia es algo que el equipo de desarrollo hace a diario.

87
00:08:43,080 --> 00:08:54,080
Y es importante porque parece que es poco, el problema es el efecto de multiplicación que tiene cuando tienes una escala muy grande.

88
00:08:54,080 --> 00:09:03,080
Y luego, esta es la clave, el change management. Decíamos antes que un sistema que no cambia es un sistema que no falla al final de cabo,

89
00:09:03,080 --> 00:09:08,080
o sea, algo que haya externalidades y demás, pero generalmente la gran mayoría de los incidentes que veis,

90
00:09:08,080 --> 00:09:15,080
y a nosotros nos ha pasado, vienen por cambios que ocurren en el propio sistema. Por ejemplo, cuando vais a desplegar un...

91
00:09:15,080 --> 00:09:22,080
Cuando vais a desplegar un nuevo binario, por ejemplo, tendréis que hacer una validación. Tendréis un entorno de QA, por ejemplo,

92
00:09:22,080 --> 00:09:29,080
tendréis un entorno de... Ah, si estoy allí, no, y aquí sí, va. Un entorno de QA, tendréis, por ejemplo, validaciones de Canary,

93
00:09:29,080 --> 00:09:34,080
tendréis métricas que estáis cogiendo. Si vais a desplegar un modelo nuevo de Machine Learning, por ejemplo,

94
00:09:34,080 --> 00:09:38,080
tendréis que hacer, yo no soy muy experto de esto, pero tendréis que hacer las validaciones de calidad suficientes al modelo

95
00:09:38,080 --> 00:09:46,080
para poder ponerlo en producción y demás. En muchas de las ocasiones, tenéis que tener en cuenta que todos los tests que estés haciendo,

96
00:09:46,080 --> 00:09:53,080
absolutamente todos, son mentira, porque el único test verdadero que hay es producción. Todos los entornos anteriores que hay a producción

97
00:09:53,080 --> 00:09:58,080
tienen otras características, tienen menos escala, tienen menos carga, tienen menos dependencias.

98
00:09:58,080 --> 00:10:05,080
Entonces, un evento pones en producción cuando realmente estás probando el software que estás haciendo y si rompe, claro,

99
00:10:05,080 --> 00:10:11,080
pues es un poco un Cristo. Entonces, tenemos también, por ejemplo, herramientas que nos pueden interceder un rollback automáticamente

100
00:10:11,080 --> 00:10:19,080
cuando las cosas no funcionan bien en producción y demás. Todas estas herramientas, o una gran mayoría de estas, empezaron siendo escritas en país.

101
00:10:19,080 --> 00:10:29,080
Bueno, esto lo que hablábamos antes de entrar. Entonces, ahora ya vamos un poquito al solo mío, que es el cómo en SRI hacemos software.

102
00:10:29,080 --> 00:10:36,080
Hay un libro de SRI que explica un poco varias cosas. Yo he traído solo tres casos de uso y entonces ahora, pues, procedo a contar la vida

103
00:10:36,080 --> 00:10:42,080
de estos casos de uso. Si tenéis preguntas, habrá al final, pero podéis interrumpirme también, que total, tampoco necesitamos esperar.

104
00:10:42,080 --> 00:10:50,080
La forma en la que SRI hace software es bastante distinta a la forma en la que los ingenieros de software tradicionales hacen software,

105
00:10:50,080 --> 00:10:58,080
por un motivo, o por dos motivos en especial. Es primero, el bref, o a la anchura de lo que nosotros tenemos que soportar,

106
00:10:58,080 --> 00:11:07,080
es mucho más grande que lo que soporta un equipo de software tradicional. Dentro de Google, un equipo de software de entre 6 y 8 o 9 personas,

107
00:11:07,080 --> 00:11:13,080
por ejemplo, puede estar soportando una funcionalidad concreta que puede llegar a tener a lo mejor 6 microservicios y una base de datos de SRI.

108
00:11:13,080 --> 00:11:23,080
Bien, el equipo de SRI está soportando toda la funcionalidad para un producto concreto. Por ejemplo, nosotros en Identity soportamos todos estos microservicios,

109
00:11:23,080 --> 00:11:32,080
pero la gente de Gmail va a soportar toda la pila de Gmail desde el frontend, todos los capas intermedias del business logic,

110
00:11:32,080 --> 00:11:38,080
y luego va a tener un número indeterminado pero grande de almacenamientos de distintas propiedades, desde un equivalient store,

111
00:11:38,080 --> 00:11:48,080
por ejemplo, para las cuentas de usuario, los cachés, hasta una base de datos grande de Spanish, donde están los mensajes, por ejemplo, de Gmail de hecho.

112
00:11:48,080 --> 00:11:55,080
Entonces esto te da una perspectiva diferente a cómo el software tiene que interactuar con unos componentes con los otros.

113
00:11:55,080 --> 00:12:04,080
Entonces te da una perspectiva para saber cuál es el mejor orden de despliegue, por ejemplo, o cuál es el mejor lugar para desplegar servicios,

114
00:12:04,080 --> 00:12:10,080
como por ejemplo, de Workspace o lo que sea. La otra diferencia es la profundidad.

115
00:12:10,080 --> 00:12:20,080
Nosotros hemos escrito parches para un depurador. Hemos encontrado un bug en el kernel, que eso es bastante guapo y difícil de depurar,

116
00:12:20,080 --> 00:12:27,080
pero al final no es solo tu parcela de funcionalidad concreta o un API concreto, en ese sentido nosotros estamos soportando productos completos.

117
00:12:27,080 --> 00:12:37,080
Tiene la ventaja, tiene la dificultad de que eso es más complejo de entender, pero tiene la ventaja de que nosotros estamos realmente en contacto con el usuario,

118
00:12:37,080 --> 00:12:43,080
porque nosotros lo que hacemos es entender cuál es el producto y la funcionalidad que los usuarios necesitan.

119
00:12:43,080 --> 00:12:49,080
Entonces sí que entendemos, por ejemplo, bien cuál es el objetivo de disponibilidad que tiene que tener un servicio.

120
00:12:49,080 --> 00:12:56,080
Cuando vas a hablar con un product manager y le dices, bueno, vamos a lanzar este servicio, cuánta disponibilidad deberíamos tener.

121
00:12:56,080 --> 00:13:00,080
Y el product manager te va a decir, bueno, pues esto es importantísimo, tiene que tener 7,9 y medio.

122
00:13:00,080 --> 00:13:05,080
Entonces, lo dices, bueno, bien, ya empezamos. Entonces, lo dices, muy bien, eso se puede hacer.

123
00:13:05,080 --> 00:13:10,080
Se puede tener un servicio de 7, 8, 9, la disponibilidad que uno quiera, infinito, bueno, infinito no, pero mucho.

124
00:13:10,080 --> 00:13:18,080
Entonces tú le dices el product manager, vamos a necesitar 450 ingenieros, 100 series y aproximadamente 10 millones de CPUs.

125
00:13:18,080 --> 00:13:26,080
Para tener toda la réplica y demás. Entonces el product manager dice, bueno, no, igual 7, 9, entonces vas bajando

126
00:13:26,080 --> 00:13:32,080
hasta que encuentras cuál es el punto medio entre lo que los usuarios necesitan y esperan, el coste de desarrollo

127
00:13:32,080 --> 00:13:35,080
y la operatividad de ese software.

128
00:13:38,080 --> 00:13:42,080
Ahora vamos a ir con varios casos de uso, varios casos de estudio, perdón.

129
00:13:42,080 --> 00:13:51,080
Tengo tres, uno es un sistema que permite optimizar toda la flota de despliegue de servicios, de máquinas y la topología de red.

130
00:13:51,080 --> 00:13:58,080
Tengo otro que es el sistema de CI CD que teníamos, se llamaba Sysifus, que estaba escrito en Python.

131
00:13:58,080 --> 00:14:03,080
Y tengo otro que es el sistema de monitorización que tenemos que se llama Monarch.

132
00:14:03,080 --> 00:14:09,080
Cada uno de ellos tiene diferentes propiedades y está en diferente nivel de maduridad, si eso es una palabra.

133
00:14:09,080 --> 00:14:18,080
Oxon es un software que es clave para poder tener una flota óptima. Lo que hace es lo siguiente, simplemente es

134
00:14:18,080 --> 00:14:25,080
resuelve o optimiza un problema con restricciones al final.

135
00:14:25,080 --> 00:14:32,080
Entonces, ¿cuáles son las restricciones? Primero va a tener una copia o va a tener una visión de cuál es el estado de la flota

136
00:14:32,080 --> 00:14:40,080
de computadores que tienes. Es decir, va a tener, por ejemplo, unos sistemas de configuración y una serie de snapshots

137
00:14:40,080 --> 00:14:47,080
y demás que le dicen cuántas máquinas están disponibles, cuál es la fiabilidad de cada máquina, cuál es el ancho de banda de red

138
00:14:47,080 --> 00:14:55,080
dentro de los clusters, en el backbone, cuál es el por dónde están llegando los usuarios, es decir, cuál es el tráfico de ingreso

139
00:14:55,080 --> 00:15:01,080
que tenemos desde, por ejemplo, en Europa, el tráfico que tenemos en Estados Unidos, el tráfico que hay en Sudamérica.

140
00:15:01,080 --> 00:15:07,080
Va a tener otra información, por ejemplo, como puede ser el rendimiento del servidor. Es decir, no es lo mismo tener un servidor

141
00:15:07,080 --> 00:15:17,080
que puede hacer 15.000 consultas por CPU por segundo que un servidor que puede hacer 600, es otro nivel de restricciones.

142
00:15:17,080 --> 00:15:26,080
Y luego va a tener otras restricciones que son las establecidas para, por ejemplo, alcanzar objetivos de fiabilidad.

143
00:15:26,080 --> 00:15:35,080
Y eso de los casos es redundancia. Es decir, tú vas a querer establecer un servicio en el que tienes que tener la capacidad de tener

144
00:15:35,080 --> 00:15:42,080
N++, no sé si os familiares con ese término, por cada continente. N++ significa que yo quiero tener tantos clusters o tantos

145
00:15:42,080 --> 00:15:48,080
deditas en test o tantas réplicas de mi software, como sea necesario, de tal manera que si en cualquier momento dos de ellas

146
00:15:48,080 --> 00:15:56,080
están accesibles, porque en el CortR, porque en un centro de datos que no funciona, porque X, puedo seguir absorbiendo el 100%

147
00:15:56,080 --> 00:16:04,080
de la capacidad de demandada por los usuarios en ese momento. Normalmente los servicios de Google se despliegan en N++

148
00:16:04,080 --> 00:16:10,080
y N++ uno continental, de manera que si perdemos cualquier centro de datos dentro de un continente es transparente,

149
00:16:10,080 --> 00:16:18,080
absoluto para el usuario y si perdemos dos globales, un centro de datos calcular que puede tener entre 50 y 100.000 máquinas.

150
00:16:18,080 --> 00:16:28,080
Es una cosa bastante gorda. Si perdiendo dos globales todavía se puede absorber la capacidad de los usuarios sin que haya ningún outage.

151
00:16:28,080 --> 00:16:38,080
Bien, esto parece algo sencillo. El problema es que estamos hablando de a lo mejor 15.000, 20.000 restricciones en las que tenemos que optimizar

152
00:16:38,080 --> 00:16:45,080
para minimizar el costo, es decir, minimizar la cantidad de réplicas, la cantidad de storage o la cantidad de red que se está utilizando.

153
00:16:45,080 --> 00:16:57,080
Una de las ventajas que tenía Oxford o que tiene es que el kernel del software está escrito 11.000 más por rendimiento y demás,

154
00:16:57,080 --> 00:17:05,080
pero todos los fiches de configuración, todos los inputs que se hacen, se hacen con un DSL que está basado en un domain específic language

155
00:17:05,080 --> 00:17:12,080
basado en Python y que te permite establecer tus restricciones casi en formato textual. No tienes que establecer código,

156
00:17:12,080 --> 00:17:20,080
entonces puedes decir que quieres establecer tus servidores con NMAS 1 o NMAS 2 réplicas,

157
00:17:20,080 --> 00:17:27,080
luego puedes establecer una serie de cosas, una serie de composiciones de reglas.

158
00:17:27,080 --> 00:17:33,080
Este es uno de los mejores ejemplos de desarrollo de software en esa ring basado en Python.

159
00:17:33,080 --> 00:17:39,080
Está integrado con un montón de datasources y es realmente potente.

160
00:17:39,080 --> 00:17:43,080
Ahora os voy a contar uno que fue una maravilla.

161
00:17:43,080 --> 00:17:50,080
Estábamos hablando de los cambios que se realizan el sistema, la gestión de los rollouts y demás.

162
00:17:50,080 --> 00:17:55,080
Un sistema de CSEDI, al final lo que hace es una integración continua y un delivery continuo.

163
00:17:55,080 --> 00:18:01,080
Si, si fuese la nuestra sistema de delivery continuo, digo era porque ha fallecido.

164
00:18:01,080 --> 00:18:06,080
Es una de las ventajas y uno de los inconvenientes que tiene Python para el desarrollo de software,

165
00:18:06,080 --> 00:18:14,080
que es muy flexible, es muy rápido para hacer prototipos y es muy accesible para todos los casi nivel de programación.

166
00:18:14,080 --> 00:18:20,080
Si, si fuese empezado como en el equipo de search, dijeron necesitamos automatizar lo que es el delivery

167
00:18:20,080 --> 00:18:26,080
y al final lo que tenía eran un montón de clusters y tenían que ejecutar una serie de reglas o una serie de comandos

168
00:18:26,080 --> 00:18:31,080
para que cada clase recibiera una versión actualizada de la pila de búsqueda.

169
00:18:31,080 --> 00:18:38,080
Entonces escribieron con Python una cosa maravillosa que era vamos a hacer un engine que simplemente va a dar vueltas

170
00:18:38,080 --> 00:18:44,080
y las personas que lo van a utilizar simplemente van a escribir dos cosas,

171
00:18:44,080 --> 00:18:49,080
que es una serie de pasos que quieren que ocurran en su CSEDI y su Continuous Delivery

172
00:18:49,080 --> 00:18:52,080
y cada uno de estos pasos puede ser custom.

173
00:18:52,080 --> 00:18:59,080
Tenemos una serie de herramientas que son bien conocidas, vale, como yo que sé la de Usamos Borg,

174
00:18:59,080 --> 00:19:04,080
que es los que seáis familiares con Kubernetes, conocéis el QTL,

175
00:19:04,080 --> 00:19:10,080
pues el equivalente para lanzar trabajos en Borg o lo que sea y así.

176
00:19:10,080 --> 00:19:19,080
Pero permitieron que cada equipo tuviera la flexibilidad de escribir plugins para sus propias herramientas,

177
00:19:19,080 --> 00:19:24,080
lo cual es lo que le dio la potencia máxima y absoluta a Sissibus, ahí veis un ejemplo de un rollout,

178
00:19:24,080 --> 00:19:32,080
entonces veis que al final lo que hay son una serie de pasos para hacer un rollout de las siguientes cosas que hay que hacer,

179
00:19:32,080 --> 00:19:35,080
cada uno de estos era un plugin y demás.

180
00:19:35,080 --> 00:19:38,080
Esa potencia que tenía Python en su momento para poder extenderlo

181
00:19:38,080 --> 00:19:44,080
hizo que casi toda la empresa en menos de un año adoptara Sissibus para todos los rollouts.

182
00:19:44,080 --> 00:19:49,080
Yo me acuerdo de uno de los primeros proyectos que tuve que hacer fue escribir mis Sissibus para nuestro servicio,

183
00:19:49,080 --> 00:19:52,080
que por entonces eran solo tres servicios.

184
00:19:52,080 --> 00:19:55,080
Y era fantástico porque tú te sentabas, escribías tus plugins, escribías tus cosas,

185
00:19:55,080 --> 00:20:00,080
y al final lo que hacías era encapsular el conocimiento que tenía el equipo para hacer los rollouts en Sissibus.

186
00:20:00,080 --> 00:20:02,080
¿Cuál era el problema?

187
00:20:02,080 --> 00:20:10,080
Esa potencia fue lo que lo mató y es que encontramos que mantener bases de código

188
00:20:10,080 --> 00:20:15,080
en las que muchos ingenieros, estamos hablando de que Sarri por entonces tenía unas mil quinientas personas

189
00:20:15,080 --> 00:20:18,080
y a lo mejor un tercio de ellas estaba escribiendo código,

190
00:20:18,080 --> 00:20:22,080
o sea que a lo mejor quinientas personas estaban escribiendo commits para toda esta base de código,

191
00:20:22,080 --> 00:20:24,080
es muy complicada.

192
00:20:24,080 --> 00:20:30,080
Tiene una flexibilidad muy buena para poder avanzar y para poder desarrollar cosas rápidamente,

193
00:20:30,080 --> 00:20:34,080
pero sin embargo la mantenibilidad de ese código, la calidad del código,

194
00:20:34,080 --> 00:20:40,080
se declinaba rapidísimamente porque cada persona escribía sus plugins, cosas duplicadas,

195
00:20:40,080 --> 00:20:45,080
no es lo mismo, una persona escribió el código de una forma, la otra, y entonces era complicada.

196
00:20:45,080 --> 00:20:47,080
¿Qué se hizo por entonces?

197
00:20:47,080 --> 00:20:52,080
Se hicieron dos esfuerzos que merecen la pena si alguno de vosotros tenéis una base de código de Python

198
00:20:52,080 --> 00:20:55,080
muy grande o con mucha gente está iterando,

199
00:20:55,080 --> 00:20:57,080
fue utilizar los...

200
00:20:57,080 --> 00:21:00,080
Bueno, primero se migró a Python 3, que fue un dolor,

201
00:21:00,080 --> 00:21:04,080
y luego una vez estuvimos ahí, una de las metajas que teníamos, que teníamos todo el tema de typing

202
00:21:04,080 --> 00:21:08,080
y todas las anotaciones de tipos, eso ayudó muchísimo,

203
00:21:08,080 --> 00:21:11,080
porque cuando conseguimos hacer todas las anotaciones de tipos,

204
00:21:11,080 --> 00:21:15,080
se puede hacer un análisis sintáctico, estático, sobre el código que se va a ejecutar,

205
00:21:15,080 --> 00:21:17,080
entonces podrías predecir si...

206
00:21:17,080 --> 00:21:20,080
Bueno, puede haber fallos, si alguna de las, por ejemplo,

207
00:21:20,080 --> 00:21:25,080
una de las cosas que fallaba cuando teníamos que hacer un release de CIFUS,

208
00:21:25,080 --> 00:21:28,080
era algo tan sencillo como no ejecutarte desde unidad,

209
00:21:28,080 --> 00:21:30,080
simplemente interpretar el código,

210
00:21:30,080 --> 00:21:35,080
coger un intérprete y decir cargar el código para ver si es sintácticamente correcto.

211
00:21:35,080 --> 00:21:39,080
Eso era, todos los días estaba roto, ¿vale?

212
00:21:39,080 --> 00:21:41,080
Entonces, bueno, había desde unidad lo que sea,

213
00:21:41,080 --> 00:21:44,080
pero bueno, hacia el problema que la realisis que nosotros hacíamos de CIFUS,

214
00:21:44,080 --> 00:21:46,080
pues se alargaban y era un dolor,

215
00:21:46,080 --> 00:21:51,080
simplemente con poder hacer, por ejemplo, un análisis estático del código,

216
00:21:51,080 --> 00:21:55,080
bueno, eso fue el día y la noche en relación a CIFUS.

217
00:21:55,080 --> 00:21:59,080
El otro problema que tenía CIFUS y eso fue lo que ya no se pudo,

218
00:21:59,080 --> 00:22:02,080
o se decidió reescribir la herramienta que tenemos ahora,

219
00:22:02,080 --> 00:22:06,080
tiene otro modelo de datos y más, está escrito en Go, fue la concurrencia.

220
00:22:06,080 --> 00:22:11,080
La concurrencia se convirtió en un problema después a lo largo del tiempo,

221
00:22:11,080 --> 00:22:13,080
cuando por ejemplo había cada vez más clusters,

222
00:22:13,080 --> 00:22:16,080
había cada vez más binarios, el movimiento de microservicios lo hacía complicado,

223
00:22:16,080 --> 00:22:19,080
porque entonces en lugar de hacer un release de tu binario,

224
00:22:19,080 --> 00:22:23,080
tendrías que hacer un release de un mesh de, a lo mejor, 50, 60 binarios,

225
00:22:23,080 --> 00:22:25,080
en una cantidad de clusters determinado,

226
00:22:25,080 --> 00:22:30,080
entonces eso lo convertía en bastante complicado,

227
00:22:30,080 --> 00:22:32,080
no porque fuera un sistema de high throughput,

228
00:22:32,080 --> 00:22:37,080
pero porque siempre estaba, pues bien estaba atascada,

229
00:22:37,080 --> 00:22:40,080
o bien estaba, hacer un release será complicado.

230
00:22:40,080 --> 00:22:42,080
Entonces en este caso, una de las desfaces que se tomó,

231
00:22:42,080 --> 00:22:44,080
yo creo que correctamente fue reescribirlo,

232
00:22:44,080 --> 00:22:48,080
un sistema con además un modelo de datos diferente en Go.

233
00:22:48,080 --> 00:22:52,080
Y el último caso de uso que está aquí es Monarch.

234
00:22:52,080 --> 00:22:57,080
Si vosotros conocéis Prometheus, los que tengáis familiaridad con Kubernetes y demás,

235
00:22:57,080 --> 00:23:01,080
Monarch es, bueno, procede de Borgman,

236
00:23:01,080 --> 00:23:04,080
Borgman es el Borgman monitony system,

237
00:23:04,080 --> 00:23:06,080
ya veis que los nombres no es que sean muy originales,

238
00:23:06,080 --> 00:23:09,080
el Borg es el Kubernetes, digamos, interno.

239
00:23:09,080 --> 00:23:13,080
Borgman, perdón, tenía una serie de problemas,

240
00:23:13,080 --> 00:23:16,080
porque la sintaxis se vio escogido para escribir las reglas de monetización,

241
00:23:16,080 --> 00:23:20,080
era peor que Perl, muy malo.

242
00:23:20,080 --> 00:23:23,080
Entonces, bueno, vamos a hacer una cosa bien, vamos a hacerlo con Monarch.

243
00:23:23,080 --> 00:23:25,080
Monarch tiene una arquitectura muy similar,

244
00:23:25,080 --> 00:23:29,080
si conocéis Thanos, por ejemplo, en relación a Prometheus, es lo mismo,

245
00:23:29,080 --> 00:23:33,080
hay un sistema global que está en la empresa como servicio,

246
00:23:33,080 --> 00:23:35,080
entonces tú escribes tus reglas,

247
00:23:35,080 --> 00:23:37,080
quieres que eres tus reglas para hacer dos cosas,

248
00:23:37,080 --> 00:23:40,080
tienes que escribir reglas para definir métricas,

249
00:23:40,080 --> 00:23:43,080
que tú quieres que el sistema recolecte en las localizaciones que tú quieras,

250
00:23:43,080 --> 00:23:48,080
tienes que escribir reglas para hacer computaciones con esas métricas,

251
00:23:48,080 --> 00:23:50,080
por ejemplo, puedes definir una métrica,

252
00:23:50,080 --> 00:23:53,080
que sería cuál es la latencia con la que estás sirviendo este servicio,

253
00:23:53,080 --> 00:23:58,080
y luego hacer una computación que convierta eso en un indicador de nivel de servicio, por ejemplo.

254
00:23:58,080 --> 00:24:01,080
Puedes estar recogiendo la latencia de tu frontend,

255
00:24:01,080 --> 00:24:03,080
de las peticiones que son satisfactores,

256
00:24:03,080 --> 00:24:07,080
es una métrica, una precomputación sería convertir eso,

257
00:24:07,080 --> 00:24:10,080
en cuál es el porcentaje o el ratio de peticiones

258
00:24:10,080 --> 00:24:14,080
que están siendo servidas por una latencia inferior a 200 milisegundos,

259
00:24:14,080 --> 00:24:18,080
que es mi SLO, eso serían las computaciones.

260
00:24:18,080 --> 00:24:23,080
Y luego, la tercera pata que tienes, que tú escribirías código para hacer dashboards,

261
00:24:23,080 --> 00:24:26,080
para visualizar eso y código para generar alertas.

262
00:24:26,080 --> 00:24:32,080
La recolección o la definición de métricas se hace en Python,

263
00:24:32,080 --> 00:24:35,080
se hace con un framework que llamamos GEMON, Google Monitony,

264
00:24:35,080 --> 00:24:37,080
a la vez lo piensan mucho,

265
00:24:37,080 --> 00:24:41,080
y una de las ventajas, por ejemplo, que tenía Python,

266
00:24:41,080 --> 00:24:44,080
al ser tan exsensibles que podía permitir a cada uno de los equipos

267
00:24:44,080 --> 00:24:47,080
tener sus propios dashboards, que estaban basados en un software que se llamaba Bice Roy,

268
00:24:47,080 --> 00:24:49,080
que estaba basado en Django.

269
00:24:49,080 --> 00:24:52,080
Entonces, cada equipo tenía una especie de framework general,

270
00:24:52,080 --> 00:24:56,080
y tú podías simplemente escribir las plantillas de Django

271
00:24:56,080 --> 00:24:58,080
y obtener directamente todas las métricas,

272
00:24:58,080 --> 00:25:03,080
si te da agregaciones, te da, por ejemplo, herramientas para agrupar,

273
00:25:03,080 --> 00:25:06,080
para hacer filtros, todas estas cosas de una manera muy sencilla.

274
00:25:06,080 --> 00:25:11,080
No necesitas pasarte toda la vida escribiendo un dashboard personalizado,

275
00:25:11,080 --> 00:25:15,080
simplemente con hacer una plantilla de Django, por ejemplo, lo tenías.

276
00:25:15,080 --> 00:25:18,080
Y eso es una de las ventajas que, por ejemplo,

277
00:25:18,080 --> 00:25:23,080
para este caso de Monarch, Python proporcionaba.

278
00:25:23,080 --> 00:25:27,080
En este caso, para este software, ya desde el principio,

279
00:25:27,080 --> 00:25:31,080
establecieron una guía de estilo y establecieron una serie de restricciones

280
00:25:31,080 --> 00:25:34,080
a lo que se podía hacer y lo que no se podía hacer con Python,

281
00:25:34,080 --> 00:25:39,080
ya que con los años, el código, la calidad de la base de código,

282
00:25:39,080 --> 00:25:43,080
no degradaba como degradó, por ejemplo, con el caso de Sisyphus.

283
00:25:43,080 --> 00:25:47,080
Es decir, si desde el principio estableces reglas para la forma de los tipos,

284
00:25:47,080 --> 00:25:50,080
desde el principio piensas un poco cómo tiene que ser el API

285
00:25:50,080 --> 00:25:52,080
que tú ofreces a los usuarios,

286
00:25:52,080 --> 00:25:54,080
en este caso los equipos que iban a desarrollar,

287
00:25:54,080 --> 00:25:57,080
a recolezar métricas o a desarrollar dashboards,

288
00:25:57,080 --> 00:26:02,080
con el tiempo, la calidad del código, la mantenibilidad,

289
00:26:02,080 --> 00:26:07,080
y demás, sí que se puede mantener de forma alta.

290
00:26:11,080 --> 00:26:13,080
Y ya está.

291
00:26:15,080 --> 00:26:17,080
Nos quejeis que os he recuperado.

292
00:26:17,080 --> 00:26:32,080
Antes de las preguntas, os recomiendo este libro.

293
00:26:32,080 --> 00:26:35,080
Hay otro más que se va a salir ahora para Machine Learning.

294
00:26:35,080 --> 00:26:39,080
El primero es como la teoría, luego el segundo es como vamos a llevarlo a la práctica,

295
00:26:39,080 --> 00:26:44,080
luego hay una cosa de seguridad que es otra de la cara de la moneda de los servicios viables.

296
00:26:44,080 --> 00:26:48,080
Hay uno que va a salir ahora dentro de poco, que es de Machine Learning.

297
00:26:48,080 --> 00:26:52,080
Entonces sería cómo poner producción y cómo utilizar técnicas de desarrollo y demás

298
00:26:52,080 --> 00:26:57,080
para tener servicios de Machine Learning de alta escala, modelos y todas estas cosas.

299
00:26:59,080 --> 00:27:01,080
Muchas gracias Ram.

300
00:27:01,080 --> 00:27:04,080
Es súper interesante y llegó mucho detalle, así que está muy bueno.

301
00:27:04,080 --> 00:27:09,080
Tenemos cinco minutillos para preguntas, así que podemos tratar de que tengamos una.

302
00:27:09,080 --> 00:27:14,080
Me voy a mover un poco para acá, que es que me está dando el foco en la cabeza.

303
00:27:18,080 --> 00:27:23,080
Hola, buenas. La charla más encantada ha estado muy bien, así que muchas gracias.

304
00:27:23,080 --> 00:27:28,080
Mi pregunta es sobre, has hablado de los tres ejemplos, la degradación del código,

305
00:27:28,080 --> 00:27:30,080
no de la base de código.

306
00:27:30,080 --> 00:27:39,080
¿Cómo medíais esa degradación con alguna librería de Python, de CodeComplexity o algo así?

307
00:27:39,080 --> 00:27:44,080
Varias cosas. Hay medidas de CodeComplexity que se hacen, ¿vale?

308
00:27:44,080 --> 00:27:48,080
Hasta que no puedes hacer un poco de análisis estático decente,

309
00:27:48,080 --> 00:27:53,080
pues tampoco te ofrece mucho porque te dice, este código tiene una complejidad, no sé qué.

310
00:27:53,080 --> 00:27:55,080
Pero sí que se hace.

311
00:27:55,080 --> 00:28:01,080
Y luego se combina con, por ejemplo, ¿cuántas veces un commit tiene que ser rollback en el código?

312
00:28:01,080 --> 00:28:05,080
Cosas muy sencillas que te dicen que si tú cada vez que haces un commit,

313
00:28:05,080 --> 00:28:10,080
alguien tiene que venir y deshacerlo porque rompe tu sistema,

314
00:28:10,080 --> 00:28:12,080
indica que la calidad del código no es buena.

315
00:28:12,080 --> 00:28:17,080
Luego tienes medidas como, por ejemplo, ¿cuántas veces un release que quieres hacer de Sysifus

316
00:28:17,080 --> 00:28:21,080
o del código que fuera no llega a fin, a producción?

317
00:28:21,080 --> 00:28:25,080
Y cosas así. Al final, lo que teníamos es un montón de medidas,

318
00:28:25,080 --> 00:28:27,080
que es un rollo para que tienes que mirar todas,

319
00:28:27,080 --> 00:28:32,080
entonces hubo un equipo de la gente de Engineering Productivity que las agrupó todas

320
00:28:32,080 --> 00:28:37,080
y te daba una medida que se llamaba pH, que te decía cuánto, en qué extremo estaba el software.

321
00:28:37,080 --> 00:28:40,080
Tenías como 5 puntos y si estaba en cero es como no, no,

322
00:28:40,080 --> 00:28:43,080
y si estaba en 5 pues bien, y luego por el medio pues...

323
00:28:43,080 --> 00:28:45,080
Gracias.

324
00:28:45,080 --> 00:28:48,080
Por ahí tenemos otro pregunta.

325
00:28:48,080 --> 00:28:53,080
Este es el gerente del software que se nos ha despechado.

326
00:28:53,080 --> 00:28:58,080
Gracias.

327
00:28:58,080 --> 00:29:04,080
Tenía curiosidad sobre qué medidas utilizan para prevenir

328
00:29:04,080 --> 00:29:10,080
que estos sistemas automatizados se salgan de control

329
00:29:10,080 --> 00:29:14,080
y empiecen a hacer resastres en infraestructura.

330
00:29:14,080 --> 00:29:19,080
Siempre se escucha que alguna empresa tenía un bug en su sistema de deployment

331
00:29:19,080 --> 00:29:27,080
automatizado y sale de control y empiecen a hacer cosas que terminan siendo muy dañinas.

332
00:29:27,080 --> 00:29:29,080
Eso nos pasa.

333
00:29:29,080 --> 00:29:34,080
Al final, las pruebas que tú haces de cualificación del software que tengas,

334
00:29:34,080 --> 00:29:38,080
sea un software tradicional, transaccional o algo de Machine Learning,

335
00:29:38,080 --> 00:29:43,080
lo tienes que hacer a priori y luego tienes que tener, o sea tienes que tener dos componentes,

336
00:29:43,080 --> 00:29:47,080
todos los test que tú puedas tener a priori pues te van a ayudar a tener confianza,

337
00:29:47,080 --> 00:29:50,080
pero luego lo que tienes que tener es...

338
00:29:50,080 --> 00:29:55,080
En Brave, como es eso, aceptar que el software cuando llega a producción va a fallar,

339
00:29:55,080 --> 00:30:00,080
eso es, no solo por el software porque si no la máquina se rompe, la red se rompe, lo que sea,

340
00:30:00,080 --> 00:30:03,080
entonces lo que tienes que tener son herramientas para volver atrás

341
00:30:03,080 --> 00:30:07,080
y para restaurar el estado anterior del sistema muy rápido.

342
00:30:07,080 --> 00:30:10,080
No sé si te respondo al pregunta.

343
00:30:10,080 --> 00:30:21,080
Bueno, estaba imaginando que con OXON la facilidad que os daba

344
00:30:21,080 --> 00:30:26,080
a describir vuestros plugins para vuestros componentes, el problema no era solo la calidad del código,

345
00:30:26,080 --> 00:30:29,080
sino imagino que también la reutilización de componentes.

346
00:30:29,080 --> 00:30:33,080
No sé si de todos estos plugins o como lo llamarais,

347
00:30:33,080 --> 00:30:38,080
qué ventajas o qué beneficios o qué habéis trabajado en ese sentido.

348
00:30:38,080 --> 00:30:41,080
La ventajara que la adopción era súper fácil,

349
00:30:41,080 --> 00:30:47,080
o sea, tú querías hacerte un sistema de CD rápidamente y lo tenías todo, tenías todos los ingredientes

350
00:30:47,080 --> 00:30:51,080
y no tenías que... Es como modelo muy open source, en este caso, no tienes que pedir permiso a nadie,

351
00:30:51,080 --> 00:30:57,080
tú cogías tus librerías, tus bases, tus cosas básicas, especificadas tu rollout,

352
00:30:57,080 --> 00:30:59,080
que además no tenías que cambiar el procedimiento,

353
00:30:59,080 --> 00:31:03,080
por el día es reflejar todo tal cual estaba, aunque no tuviera sentido, lo hacía,

354
00:31:03,080 --> 00:31:06,080
y luego si te faltaban plugins, tú los podías desarrollar.

355
00:31:06,080 --> 00:31:10,080
Efectivamente estoy contigo, no es solo el framework, no solo es la calidad del código,

356
00:31:10,080 --> 00:31:14,080
sino que había muchos equipos que no hablaban entre otros desarrollando la misma historia.

357
00:31:14,080 --> 00:31:19,080
Entonces, claro, uno de los plugins a lo mejor para hacer Kip City, lo que fuera,

358
00:31:19,080 --> 00:31:24,080
tenía tracción, se mantenía y tal, y luego había seis equipos que utilizaban la otra versión,

359
00:31:24,080 --> 00:31:28,080
y era un dolor. Y luego además, una vez, sí que tenía una desmentaja,

360
00:31:28,080 --> 00:31:32,080
es que una vez lo adoptabas y una vez tenías tus rollouts y demás, era complejo.

361
00:31:32,080 --> 00:31:36,080
Por ejemplo, cuando el equipo que mantenía el framework quería hacer algún cambio,

362
00:31:36,080 --> 00:31:41,080
quería migrar de país dos a tres, tenías que ir un equipo después de otro,

363
00:31:41,080 --> 00:31:46,080
pues diciéndoles cómo se hacía y que hicieran lo que les correspondía en su lado y demás.

364
00:31:46,080 --> 00:31:50,080
Entonces, al final, la gobernanza y todas estas cosas de lo que se proyectó era un Cristo.

365
00:31:50,080 --> 00:31:57,080
Sí, no es solo el framework, pero bueno, al final eso se proyecta al resto de...

366
00:31:57,080 --> 00:32:02,080
Pues ya nos tenemos más tiempo, muchas gracias Ramón de Lugo.

367
00:32:02,080 --> 00:32:28,080
Gracias.

